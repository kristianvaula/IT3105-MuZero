environment: 'snakepac' # 'snakepac' or other when implemented
logging: True
load_model: False
save_model: True

snakepac:
  num_episodes: 50
  num_episode_step: 20
  training_interval: 5
  num_simulations: 100
  I_t: 10
  batch_size: 32
  world_length: 10
  seed: 42
  action_space: &action_size_snakepac 3
  uMCTS:
    num_searches: 20
    max_depth: 8
    ucb_constant: 1.0
    discount_factor: 0.95
  
  network:
    iteration: ""
    state_window: 1
    hidden_state_size: &hidden_size_snakepac 16
    representation:
    - type: linear
      in_features: 11 # World length * window size + 4 (corresponding actions)
      out_features: 128
      activation: relu
    - type: linear
      in_features: 128
      out_features: 64
    - type: linear
      in_features: 64
      out_features: *hidden_size_snakepac

    prediction:
      - type: linear
        in_features: *hidden_size_snakepac
        out_features: 64
        activation: relu
      - type: linear
        in_features: 64
        out_features: 32
      # second to last layer is the policy layer
      - type: linear
        in_features: 32
        out_features: *action_size_snakepac
        activation: softmax
      # last layer is the value layer
      - type: linear
        in_features: 32
        out_features: 1

    dynamics:
      - type: linear
        in_features: 17 # &hidden_size_snakepac + 1 (action)
        out_features: 128
        activation: relu
      - type: linear
        in_features: 128
        out_features: 64
      # second to last layer is the hidden state layer
      - type: linear
        in_features: 64
        out_features: *hidden_size_snakepac
      # last layer is the reward layer
      - type: linear
        in_features: 64
        out_features: 1


  

riverraid:
  num_episodes: 100
  num_simulations: 100
  training_interval: 10
  batch_size: 32

  skip_frames: 4
  action_frames: 4
  mcts:
    num_searches: 50
    max_depth: 10
    ucb_constant: 1.0
    discount_factor: 0.95

logging:

network:
  # for snakepac
  iteration: ""
  representation:
  - type: linear
    in_features: "" # Will be set by the environment
    out_features: 
    activation: relu
  - type: linear
    in_features: 128
    out_features: 64

  prediction:
    - type: linear
      in_features: 64
      out_features: 64
      activation: relu
    - type: linear
      in_features: 64
      out_features: 10

  dynamics:
    - type: linear
      in_features: 68
      out_features: 128
      activation: relu
    - type: linear
      in_features: 128
      out_features: 64
